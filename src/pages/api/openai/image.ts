// Return text generated by OpenAI API
import axios from "axios";
import sharp from "sharp";
import { NextApiRequest, NextApiResponse } from "next";
import { gptApi } from "../gptAPI";
import { logger } from "../logger";
import { ImageModel } from "@/models/imageModel";

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  logger.info("url:::::" + req.url);
  const prompt = req.body.prompt;
  const response = await gptApi.getChatOneMessage(prompt);
  res.json({ prompt: prompt, response: response });
}


export const getImagesAndSaveToDB = async (prompt: string) => {
  logger.info(":::::creating image and storing to the database")
  const response = await getImage(prompt);
  let imgRef;
  const images = [];
  // download the images and save them to the database
  for (let i = 0; i < response.length; i++) {
    const item = response[i];
    // @ts-ignore
    const fetchedImage = await axios.get(item.url, { responseType: 'arraybuffer' })
    const imageBuffer = Buffer.from(fetchedImage.data, 'binary')
    const imageType = fetchedImage.headers['content-type']
    const imageName = `${prompt.replace(/\s/g, '')}-${Math.floor(new Date().getTime() / 1000)}`;
    const id = Math.floor(Math.random() * 1000000000);
    // Compress the image using Sharp
    logger.info(":::::compressing image:::::")
    const compressedImageBuffer = await sharp(imageBuffer)
      .resize({ width: 350, height: 350, fit: 'inside' })
      .jpeg({ quality: 50 })
      .toBuffer();
    const compressedImage = compressedImageBuffer.toString('base64');

    const image = {
      id,
      prompt: prompt,
      data: compressedImage,
      contentType: imageType,
      name: imageName,
    }
    const newImage = new ImageModel(image)
    images.push({ ...image, data: `data:${imageType};base64,${compressedImage}` });
    await newImage.save().then(() => {
      logger.info(':::::image:::::saved to database')
    }).catch((err: any) => {
      logger.error(':::::image:::::not saved to database' + err)
    })
    imgRef = imageName;
  }
  return { imgRef, images };
}

const getImage = async (prompt: string, n?: number) => {
  const topicPrompt = `Generate a set of inputs for a DALL·E 2 image prompt about ${prompt}. The inputs should include a noun or topic, an emotion or attribute, a style or artistic influence, and a mood or atmosphere that all relate to the ${prompt}. The outputs should be written in a way that is suitable for use as inputs for the DALL·E 2 model. Should be outputted as a object example:
                      {
                          "noun": noun or topic,
                          "emotion": emotion or attribute,
                          "style": style or artistic influence,
                          "mood": "mood or atmosphere
                      }`;
  const topicGeneration = await gptApi.getChatOneMessage({content: topicPrompt});
  if (topicGeneration === undefined) {
    return;
  }
  const topic = JSON.parse(topicGeneration);
  const imagePrompt = `Create an illustration of ${topic?.noun} that embodies ${topic?.emotion}. ${topic?.noun} should be visually stunning and imaginative, incorporating elements of ${topic.style}. The overall scene should convey a sense of ${topic.mood}`;

  return gptApi.getImage(imagePrompt).then((response: any) => {
    logger.info(":::::image:::::done");
    return response.data.data
  }).catch((error: any) => {
    logger.error(":::::image:::::failed:::::" + error);
    return error;
  });
}